---
title: "Intro to modelling with sdmTMB"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Intro to spatiotemporal models with sdmTMB}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE, cache=FALSE}
dplyr_installed <- require("dplyr", quietly = TRUE)
ggplot_installed <- require("ggplot2", quietly = TRUE)
inla_installed <- require("INLA", quietly = TRUE)
glmmTMB_installed <- require("glmmTMB", quietly = TRUE)
pkgs <- dplyr_installed && ggplot_installed && inla_installed && glmmTMB_installed
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.asp = 0.618,
  eval = identical(Sys.getenv("NOT_CRAN"), "true") && pkgs
)
```

```{r packages, message=FALSE, warning=TRUE}
library(ggplot2)
library(dplyr)
library(sdmTMB)
```

We describe the basic steps in fitting a spatial or spatiotemporal predictive-process GLMM with TMB. This can be useful for (dynamic) species distribution models and relative abundance index standardization among many other uses. See [model description](https://pbs-assess.github.io/sdmTMB/articles/model-description.html) for full model structure and equations.

We will use built-in data for Pacific cod from a fisheries independent trawl survey. 

- The density units are kg/km^2^ as calculated from catch biomass, net characteristics, and time on bottom.
- X and Y are coordinates in UTM zone 9.
- There are columns for depth and depth squared.
- Depth was centred and scaled by its standard deviation and we've included those in the data frame so that they could be used to similarly scale the prediction grid.

```{r glimpse-pcod}
glimpse(pcod)
```

The most basic model structure possible in sdmTMB replicates glmmTMB(). 
However, sdmTMB is meant for spatial models, so first we must create the spatial mesh even if we won't actually include any spatial random effects in our first example.  
The spatial components in sdmTMB are included as random fields using a triangulated mesh with vertices, known as knots, used to approximate the spatial variability in observations. 
Bilinear interpolation is used to approximate a continuous spatial field (Lindgren et al., 2011; Rue et al., 2009) from the estimated values of the spatial surface at these knot locations to other locations including those of actual observations.
These spatial random effects are assumed to be drawn from Gaussian Markov random fields (e.g. Cressie & Wikle, 2011; Latimer et al., 2009; Lindgren et al., 2011) with covariance matrices that are constrained by MateÃÅrn covariance functions (Cressie & Wikle, 2011).

There are different options for creating the spatial mesh (see [make_mesh function description] (https://pbs-assess.github.io/sdmTMB/reference/make_mesh.html). 
We will start with relatively course mesh for a balance between speed and accuracy (`cutoff = 10` where cutoff is in the units of X and Y (km here) and represents the minimum distance between points before a new mesh vertex is added). 
Smaller values create meshes with more knots.
You will likely want to use a higher resolution mesh (more knots) for some scenarios but care must be taken to avoid overfitting (see [Identifying spatial complexity in sdmTMB models](https://pbs-assess.github.io/sdmTMB/articles/how-many-knots.html).
The circles represent observations and the vertices are the knot locations.

```{r spde, fig.asp=0.8}
mesh <- make_mesh(pcod, c("X", "Y"), cutoff = 10)
plot(mesh)
```

Here is a logistic regression of pacific cod occupancy as a function of survey year (as a factor ), depth, and depth squared conducted first in sdmTMB without any spatial or spatiotemporal random effects (spatial = "off"): 

```{r basic-logistic}
m <- sdmTMB(
  data = pcod,
  formula = present ~ depth_scaled + depth_scaled2,
  mesh = mesh,
  family = binomial(link = "logit"),
  spatial = "off"
)
m
AIC(m)
```

And for comparison the same model in glmmTMB: 

```{r glmmTMB-logistic}
m0 <- glmmTMB::glmmTMB(
  data = pcod,
  formula = present ~ depth_scaled + depth_scaled2 ,
  family = binomial(link = "logit")
)
summary(m0)
```

Notice that AIC, logLik, parameter estimates, and SE are all equivalent.


Next, we can incorporate just spatial random effects into the above model by changing spatial to "on" and see that this changes coefficient estimates .

```{r spatial-logistic}
m1 <- sdmTMB(
  data = pcod,
  formula = present ~ depth_scaled + depth_scaled2 ,
  mesh = mesh,
  family = binomial(link = "logit"),
  spatial = "on"
)
m1
AIC(m1)
```

To add spatiotemporal random fields to this model we need to include both the time argument that indicates what column of your dataframe contains the time slices for at which spatial random fields should be estimated (e.g., time = "year) and we need to choose whether these fields are independent and identically distributed (spatiotemporal = "IID"), first-order autoregressive (spatiotemporal = "AR1"), or as a random walk (spatiotemporal = "RW"). We will stick with IID for these examples. 

```{r spatiotemporal-logistic}
m2 <- sdmTMB(
  data = pcod,
  formula = present ~ depth_scaled + depth_scaled2 ,
  mesh = mesh,
  family = binomial(link = "logit"),
  spatial = "on",
  time = "year",
  spatiotemporal = "IID"
)
m2
AIC(m2)
```

We can also model biomass density using a Tweedie distribution:

```{r tweedie}
m3 <- sdmTMB(
  data = pcod,
  formula = density ~ depth_scaled + depth_scaled2 ,
  mesh = mesh,
  family = tweedie(link = "log"),
  spatial = "on",
  time = "year",
  spatiotemporal = "IID"
)
m3
AIC(m3)
```

We can view the confidence intervals on the estimated random effect parameters by using the tidy function:

```{r tweedie-re}
tidy(m3, "ran_pars", conf.int = TRUE)
```
Note that SE are not reported when coefficients are in log space, but examining the confidence intervals with give an indication of the precision of these estimates. These parameters are defined as follows: 
 
range - Parameter that controls the decay of spatial correlations. If the share_range argument is changed to FALSE and the spatial and spatiotemporal ranges will be unique, otherwise the default is for both to share the same range.

phi - Observation error scale parameter (e.g., SD in Gaussian).

sigma_O - SD of spatial process (Omega).

sigma_E	- SD of spatiotemporal process (Epsilon).

tweedie_p - Tweedie p (power) parameter; between 1 and 2.


If the model used AR1 spatiotemporal fields than:

rho	- Spatiotemporal correlation between years; should be between -1 and 1.

If the model includes a spatial_varying predictor than:

sigma_Z	- SD of spatially varying coefficient field (Zeta).


We can inspect randomized quantile residuals:

```{r residuals, fig.width = 8}
pcod$resids <- residuals(m3) # randomized quantile residuals
hist(pcod$resids)
qqnorm(pcod$resids)
abline(a = 0, b = 1)
ggplot(pcod, aes(X, Y, col = resids)) + scale_colour_gradient2() +
  geom_point() + facet_wrap(~year) + coord_fixed()
```

Now we want to predict on a fine-scale grid on the entire survey domain. There is a grid built into the package for Queen Charlotte Sound named `qcs_grid`. Our prediction grid also needs to have all the covariates that we used in the model above.

```{r glimpse-grid}
glimpse(qcs_grid)
```

Now make the predictions on new data.

We will set the `area` argument to 4 km^2^ since our grid cells are 2 km x 2 km. If some grid cells were not fully in the survey domain (or were on land), we could feed a vector of grid areas to the `area` argument that matched the number of grid cells.

```{r predictions}
predictions <- predict(m3, newdata = qcs_grid, return_tmb_object = TRUE, area = 4)
```

Let's make a small function to make maps.

```{r plot-map}
plot_map <- function(dat, column) {
  ggplot(dat, aes_string("X", "Y", fill = column)) +
    geom_raster() +
    coord_fixed()
}
```

There are four kinds of predictions that we get out of the model. First we will show the predictions that incorporate all fixed effects and random effects:

```{r plot-all-effects, fig.width = 8}
plot_map(predictions$data, "exp(est)") +
  scale_fill_viridis_c(trans = "sqrt") +
  facet_wrap(~year) +
  ggtitle("Prediction (fixed effects + all random effects)")
```
We can also look at just the fixed effects, here year:

```{r plot-fix-defects, fig.width = 6}
plot_map(predictions$data, "exp(est_non_rf)")+
  scale_fill_viridis_c(trans = "sqrt") +
  ggtitle("Prediction (fixed effects only)") 
```

We can look at the spatial random effects that represent consistent deviations in space through time that are not accounted for by our fixed effects. In other words, these deviations represent consistent biotic and abiotic factors that are affecting biomass density but are not accounted for in the model.

```{r plot-spatial-effects, fig.width = 6}
plot_map(predictions$data, "omega_s") +
  scale_fill_gradient2()+
  ggtitle("Spatial random effects only") 
```

And finally we can look at the spatiotemporal random effects that represent deviation from the fixed effect predictions and the spatial random effect deviations. These represent biotic and abiotic factors that are changing through time and are not accounted for in the model.

```{r plot-spatiotemporal-effects, fig.width = 8}
plot_map(predictions$data, "epsilon_st") +
  scale_fill_gradient2()+
  facet_wrap(~year) +
  ggtitle("Spatiotemporal random effects only") 
```

We can visualize the conditional effect of any covariates by feeding simplified dataframes to the predict function:

```{r depth-eff, fig.width = 6}
nd <- data.frame(
  depth_scaled = seq(min(pcod$depth_scaled) + 0.2, 
    max(pcod$depth_scaled) - 0.2, length.out = 100), 
  year = 2015L # a chosen year
)
nd$depth_scaled2 <- nd$depth_scaled^2

p <- predict(m3, newdata = nd, se_fit = TRUE, re_form = NA)

ggplot(p, aes(depth_scaled, exp(est), 
  ymin = exp(est - 1.96 * est_se), 
  ymax = exp(est + 1.96 * est_se))) +
  geom_line() + geom_ribbon(alpha = 0.4) +
  scale_x_continuous(labels = function(x) round(exp(x*pcod$depth_sd[1] + pcod$depth_mean[1]))) +
  coord_cartesian(expand = F) +
  labs(x="Depth (m)", y="Biomass density (kg/km2)") 
```

