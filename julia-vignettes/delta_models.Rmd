---
title: "Fitting delta models with sdmTMB including separate models and built-in function"
author: "Julia Indivero, Sean Anderson, Lewis Barnett, Philina English, Eric Ward"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Fitting delta models with sdmTMB}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE, cache=FALSE}
dplyr_installed <- require("dplyr", quietly = TRUE)
ggplot_installed <- require("ggplot2", quietly = TRUE)
inla_installed <- requireNamespace("INLA", quietly = TRUE)
pkgs <- dplyr_installed && ggplot_installed && inla_installed
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.asp = 0.618,
  eval = identical(Sys.getenv("NOT_CRAN"), "true") && pkgs
)
```

```{r packages, message=FALSE, warning=TRUE}
library(ggplot2)
library(dplyr)
library(sdmTMB)
```

sdmTMB has a built-in hurdle model (also called delta models).sdmTMB didn't used to have built-in hurdle models (also called delta models), but we can also fit the two components separately and combine the predictions.

Hurdle models are more appropriate than something like a Tweedie when there are differences in the processes controlling presence vs. abundance, or when greater flexibility to account for dispersion is required. 

Built-in hurdle models can be specified in the `family=` argument within the `sdmTMB()` function. The options include:


1. Delta-Gamma model: `family=delta_gamma()`  
Fitting a binomial presence-absence model (ie `family = binomial(link = "logit")`) and then a model for the positive catches only with a Gamma observation distribution and a log link (ie `family= Gamma(link = "log")`)

2.A delta-lognormal model: `family=delta_lognormal()`
Fitting a binomial presence-absence model (ie `family = binomial(link = "logit")`) and then a model for the positive catches only with a lognormal observation distribution and a log link (ie `family= lognormal(link = "log")`

3. A Poisson-link delta model: `family=delta_poisson_link_gamma()`
Fitting a binomial presence-absence model (`family = binomial(link = "logit")`) and then a model for the positive catches only with a Poisson observation distribution and a log link 

4. Delta-binomial model: `family=delta_truncated_nbinom2()`
Fitting a binomial presence-absence model (`family = binomial(link = "logit")`) and zero-inflated count data and a `family=truncated_nbinom(link = "log")` or `family=truncated_nbinom2(link = "log")` distribution for positive catches


To summarize:
Model Type         |Built-in delta function            | Presence-absence model            | Positive catch model                  |
-------------------|-----------------------------------|-----------------------------------|---------------------------------------|
Delta-gamma        |`family=delta_gamma()`             |`family = binomial(link = "logit")`| `family = Gamma(link = "log")`        |
Delta-lognormal    |`family=delta_lognormal()`         |`family = binomial(link = "logit")`| `family = lognormal(link = "log")`    |
Poisson-link delta |`family=delta_poisson_link_gamma()`|`family = binomial(link = "logit")`|                                       |
Delta-binomial     |`family=delta_truncated_nbinom2()` |`family = binomial(link = "logit")`|`family=truncated_nbinom(link = "log")`|


Here, we will show an example of fitting each of the delta model types with the built-in features, as well as how to build each model component separately and then combine.

We will use a dataset built into the sdmTMB package: trawl survey data for Pacific Cod in Queen Charlotte Sound, British Columbia, Canada. The density units are kg/km^2^. Here, X and Y are coordinates in UTM zone 9.

We will first create a mesh, that we will use for all the models.
```{r}
pcod_spde <- make_mesh(pcod, c("X", "Y"), cutoff = 15)
  pcod_pos <- subset(pcod, density > 0)
  pcod_spde_pos <- make_mesh(pcod_pos, c("X", "Y"), mesh = pcod_spde$mesh)
```

```{r}
 fit_dg <- sdmTMB(density ~ 1,
                     data = pcod, mesh = pcod_spde,
                     time = "year", family = delta_gamma(),
                     control = sdmTMBcontrol(newton_loops = 1)
    )
```

```{r}
  p <- predict(fit_dg, newdata = qcs_grid)
    # head(p)
    p <- predict(fit_dg, newdata = qcs_grid, type = "response")
```

```{r}
fit_dln <- sdmTMB(density ~ 1,
                      data = pcod, mesh = pcod_spde,
                      spatial = "off",
                      family = delta_lognormal())
```

```{r}
    fit_plg <- sdmTMB(density ~ 1,
                      data = pcod, mesh = pcod_spde,
                      spatial = "off",
                      family = delta_poisson_link_gamma())
```


```{r}
  fit_dtnb2 <- sdmTMB(count ~ 1,
                        data = pcod, mesh = pcod_spde, spatial = "off",
                        family = delta_truncated_nbinom2())
```

```{r}
#Will include: Include showing how to use simulate(), residuals(), predict(), tidy(), etc while picking a model or using both together.
p <- predict(fit_dg, newdata = qcs_grid)
ind_dg <- get_index(p, bias_correct = FALSE)
```


# Delta models by fitting two components separately and combining predictions

```{r glimpse-pcod}
glimpse(pcod)
```


```{r spde, fig.asp=0.7}
mesh1 <- make_mesh(pcod, c("X", "Y"), cutoff = 15)
```

It is not necessary to use the same mesh for both models, but one can do so by updating the first mesh to match the reduced data frame as shown here:

```{r, fig.asp=0.9}
dat2 <- subset(pcod, density > 0)
mesh2 <- make_mesh(dat2,
  xy_cols = c("X", "Y"),
  mesh = mesh1$mesh
)
plot(mesh2)
```

This delta-gamma model is similar to the Tweedie model in the [Intro to modelling with sdmTMB](https://pbs-assess.github.io/sdmTMB/articles/basic-intro.html) vignette, except that we will use `s()` for the depth effect. 

```{r model1, warning=FALSE}
m1 <- sdmTMB(
  formula = present ~ 0 + as.factor(year) + s(depth, k = 3),
  data = pcod,
  mesh = mesh1,
  time = "year", family = binomial(link = "logit"),
  spatiotemporal = "iid",
  spatial = "on"
)
m1
```

One can use different covariates in each model, but in this case we will just let the depth effect be more wiggly by not specifying `k = 3`. 

```{r model2, warning=FALSE}
m2 <- sdmTMB(
  formula = density ~ 0 + as.factor(year) + s(depth),
  data = dat2,
  mesh = mesh2,
  time = "year",
  family = Gamma(link = "log"),
  spatiotemporal = "iid",
  spatial = "on"
)
m2
```

We can inspect the effect of the smoothed covariate using `plot_smooth()`.

```{r model1-depth}
s1 <- plot_smooth(m1, ggplot = TRUE)
s1 + xlim(min(pcod$depth), max(pcod$depth))
```

```{r model2-depth}
s2 <- plot_smooth(m2, ggplot = TRUE)
s2 + xlim(min(pcod$depth), max(pcod$depth))
```

Next, we need some way of combining the predictions across the two models. 
If all we need are point predictions, we can just multiply the predictions from the two models after applying the inverse link:

```{r delta-pred-simple, echo=TRUE}
pred <- qcs_grid # use the grid as template for saving our predictions
p_bin <- predict(m1, newdata = qcs_grid)
p_pos <- predict(m2, newdata = qcs_grid)
p_bin_prob <- m1$family$linkinv(p_bin$est)
p_pos_exp <- m2$family$linkinv(p_pos$est)
pred$est_exp <- p_bin_prob * p_pos_exp
```

But if a measure of uncertainty is required, we can simulate from the joint parameter precision matrix using the `predict()` function with any number of simulations selected (e.g., `sims = 500`). 
Because the predictions come from simulated draws from the parameter covariance matrix, the predictions will become more consistent with a larger number of draws. 
However, a greater number of draws takes longer to calculate and will use more memory (larger matrix), so fewer draws (~100) may be fine for experimentation. 
A larger number (say ~1000) may be appropriate for final model runs.

```{r delta-pred-sim, echo=TRUE}
set.seed(28239)
p_bin_sim <- predict(m1, newdata = qcs_grid, nsim = 500)
p_pos_sim <- predict(m2, newdata = qcs_grid, nsim = 500)
p_bin_prob_sim <- m1$family$linkinv(p_bin_sim)
p_pos_exp_sim <- m2$family$linkinv(p_pos_sim)
p_combined_sim <- p_bin_prob_sim * p_pos_exp_sim
```

`p_combined_sim` is just a matrix with a row for each row of data that was predicted on and width `nsim`. 
You can process this matrix however you would like.
We can save median predictions and upper and lower 95% confidence intervals:

```{r, fig.width=5}
pred$median <- apply(p_combined_sim, 1, median)
# pred$lwr <- apply(p_combined_sim, 1, quantile, probs = 0.025)
# pred$upr <- apply(p_combined_sim, 1, quantile, probs = 0.975)
plot(pred$est_exp, pred$median)
```

```{r}
ggplot(subset(pred, year == 2017), aes(X, Y, fill = median)) +
  geom_raster() +
  coord_fixed() +
  scale_fill_viridis_c(trans = "sqrt")
```

And we can now calculate spatial uncertainty:

```{r cv}
pred$cv <- apply(p_combined_sim, 1, function(x) sd(x) / mean(x))
ggplot(subset(pred, year == 2017), aes(X, Y, fill = cv)) + # 2017 as an example
  geom_raster() +
  coord_fixed() +
  scale_fill_viridis_c(trans = "log10")
```

sdmTMB also has a function for calculating an index from those draws `get_index_sims()`.
This function is just summing biomass or abundance across grid cells for each simulation draw and for each year and then calculating quantiles on the distribution of samples.
The default for this function expects the simulations to still be in log space, so we either need to `log(p_combined)`, or we can set `agg_function = function(x) sum(x)`. 

```{r get_index}
qcs_grid$area <- 4 # all 2 x 2km
ind <- get_index_sims(p_combined_sim / 1000, # convert from kg to tonnes
  agg_function = function(x) sum(x),
  area = qcs_grid$area
)
ggplot(ind, aes(year, est)) +
  geom_line() +
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.4) +
  ylab("Biomass (t)")
```

For more on modelling for the purposes of creating an index see the vignette on [Index standardization with sdmTMB](https://pbs-assess.github.io/sdmTMB/articles/index-standardization.html).
